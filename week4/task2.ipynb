{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Multi-target single-camera (MTSC) tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from VehicleDetection import *\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from pqdm.processes import pqdm\n",
    "\n",
    "\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# Import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2_dataset_loader import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATASET = \"../datasets/aic19-track1-mtmc-train/train/\"\n",
    "SEQUENCES = [DATASET+seq+\"/\" for seq in os.listdir(DATASET)]\n",
    "CAMERAS = [[seq+cam+\"/\" for cam in os.listdir(seq)]for seq in SEQUENCES]\n",
    "SEQUENCES = [seq.replace(DATASET, \"\").replace(\"/\", \"\") for seq in SEQUENCES]\n",
    "CAMERAS = dict(zip(SEQUENCES, CAMERAS))\n",
    "\n",
    "# DEFINE SPLITS\n",
    "train = [\"S01\", \"S04\"]\n",
    "test = [\"S04\"]\n",
    "\n",
    "# Model Parameters\n",
    "selected_model = 'COCO-Detection/retinanet_R_101_FPN_3x.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video(path):\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    num_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    # Read Half the frames \n",
    "    for _ in range(num_frames//2):\n",
    "        for i in range(2):\n",
    "            frame = vidcap.read()[1]\n",
    "            if i == 0:\n",
    "                frames.append(frame.astype(np.float16)) # Reduce soze\n",
    "    return iter(frames) # Iterator\n",
    "\n",
    "def readDetections(path):\n",
    "  #Generates detection dictionary where the frame number is the key and the values are the info of the corresponding detection/s\n",
    "  \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    detections = {}\n",
    "    for line in lines:\n",
    "        data = line.split(',')\n",
    "        if data[0] in detections:\n",
    "            detections[data[0]].append(VehicleDetection(int(data[0]), int(data[1]), float(data[2]), float(data[3]), float(data[4]), float(data[5]), float(data[6])))\n",
    "        else:\n",
    "            detections[data[0]] = [VehicleDetection(int(data[0]), int(data[1]), float(data[2]), float(data[3]), float(data[4]), float(data[5]), float(data[6]))]\n",
    "\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = []\n",
    "\n",
    "# For each training seq move through cameras and extact even frames and even gt\n",
    "for i, seq in enumerate(train):\n",
    "    for j, cam in tqdm(enumerate(CAMERAS[seq]), total = len(CAMERAS[seq]), desc = f\"Processing {seq}...\"):\n",
    "        data = {}\n",
    "        data[\"base_path\"] = cam + \"frames/\" # To Save Frames\n",
    "        data[\"gt_detected\"] = readDetections(cam + \"gt/gt.txt\")\n",
    "        data[\"gt_detected\"] = {key:data[\"gt_detected\"][key] for key in data[\"gt_detected\"].keys() if int(key) % 2 == 0}\n",
    "        data[\"frames\"] = extract_video(cam + \"vdo.avi\")\n",
    "\n",
    "        seq_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    global seq_data\n",
    "    return [get_AICity_dicts(**d) for d in seq_data] # Get List of Dicts in proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "DatasetCatalog.register(\"AICity_train\" , get_dataset)\n",
    "MetadataCatalog.get(\"AICity_train\").set(thing_classes=[\"car\"])\n",
    "AICity_metadata = MetadataCatalog.get(\"AICity_train\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(selected_model))\n",
    "cfg.DATASETS.TRAIN = (\"AICity_train\",)\n",
    "#cfg.DATASETS.VAL = ('AICity_valid',)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(selected_model)  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 1e-3\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "cfg.SOLVER.STEPS = [] # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 # (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 1\n",
    "\n",
    "cfg.OUTPUT_DIR = \"./results\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "m5",
   "language": "python",
   "name": "m5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
