{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4: Color\n",
    "Support colour sequences taking advantage of the chromatic components from different color spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VehicleDetection import VehicleDetection\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pltÇ\n",
    "import random\n",
    "import copy\n",
    "import statistics\n",
    "from eval_utils import *\n",
    "from video_utils import *\n",
    "from load_utils import *\n",
    "from background_remover import *\n",
    "\n",
    "data_path = '../datasets/AICity_data/train/S03/c010/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_detect = readDetectionsXML('ai_challenge_s03_c010-full_annotation.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try RGB, HS from HSV, UV from YUV, AB from LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 410/410 [00:11<00:00, 36.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# @ 30s UOC Server\n",
    "color_spaces = {\"RGB\": cv2.COLOR_BGR2RGB,\"HSV\": cv2.COLOR_BGR2HSV, \"LAB\": cv2.COLOR_BGR2LAB, 'YUV': cv2.COLOR_BGR2YUV}\n",
    "means, stds = get_background_stats_color(data_path + 'vdo.avi', 1, 411) # 411 is the 20% of the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background_adaptative_color(means, stds, videoPath, ROIpath, alpha=4, sigma=2, p=0.1, color=\"RGB\"):\n",
    "    roi = cv2.imread(ROIpath, cv2.IMREAD_GRAYSCALE)\n",
    "    vidcap = cv2.VideoCapture(videoPath)\n",
    "    num_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    detections = {}\n",
    "    for frame in tqdm(range(num_frames)):\n",
    "        _, image = vidcap.read()\n",
    "        if frame >= num_frames // 4:\n",
    "            # Read Color Image\n",
    "            img_color = cv2.cvtColor(image, color_spaces[color])\n",
    "            # Split Channels\n",
    "            img_color_C1 = img_color[:, :, 0]\n",
    "            img_color_C2 = img_color[:, :, 1]\n",
    "            img_color_C3 = img_color[:, :, 2]\n",
    "            # Mask per Channel\n",
    "            img_mask_C1 = np.zeros(img_color_C1.shape)\n",
    "            img_mask_C2 = np.zeros(img_color_C2.shape)\n",
    "            img_mask_C3 = np.zeros(img_color_C3.shape)\n",
    "            # Compute mask with formula\n",
    "            if color == \"RGB\":\n",
    "                img_mask_C1[abs(img_color_C1 - means[0]) >= alpha * (stds[0] + sigma)] = 255\n",
    "                img_mask_C2[abs(img_color_C2 - means[1]) >= alpha * (stds[1] + sigma)] = 255\n",
    "                img_mask_C3[abs(img_color_C3 - means[2]) >= alpha * (stds[2] + sigma)] = 255\n",
    "                img_mask = img_mask_C1 + img_mask_C2 +img_mask_C3\n",
    "                # AND: just where all channels agree\n",
    "                img_mask[img_mask == 255*3] = 255\n",
    "                img_mask[img_mask != 255] = 0\n",
    "\n",
    "            print(img_mask.shape)\n",
    "            print(roi.shape)\n",
    "            cleaned = cleanMask(img_mask, roi)\n",
    "            cv2.imwrite(f'./masks_adaptative_RGB/mask_{frame}.png', cleaned)\n",
    "\n",
    "            #update mean\n",
    "            idxs = cleaned == 0\n",
    "            means[0][idxs] = p * img_color_C1[idxs] + (1 - p) * means[0][idxs]\n",
    "            means[1][idxs] = p * img_color_C2[idxs] + (1 - p) * means[1][idxs]\n",
    "            means[2][idxs] = p * img_color_C3[idxs] + (1 - p) * means[2][idxs]\n",
    "            #update std\n",
    "            stds[0][idxs] = np.sqrt(p * (img_color_C1[idxs] - means[0][idxs])**2 + (1 - p) * stds[0][idxs]**2)\n",
    "            stds[1][idxs] = np.sqrt(p * (img_color_C2[idxs] - means[1][idxs])**2 + (1 - p) * stds[1][idxs]**2)\n",
    "            stds[2][idxs] = np.sqrt(p * (img_color_C3[idxs] - means[2][idxs])**2 + (1 - p) * stds[2][idxs]**2)\n",
    "\n",
    "            detections[str(frame)] = getBoxesFromMask(cleaned)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 534/2141 [00:02<00:09, 173.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n",
      "(1080, 1920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 535/2141 [00:03<00:10, 156.41it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/core/src/arithm.cpp:212: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38197/3664916677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingleGaussianDetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_background_adaptative_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'vdo.avi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'roi.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_38197/67663459.py\u001b[0m in \u001b[0;36mremove_background_adaptative_color\u001b[0;34m(means, stds, videoPath, ROIpath, alpha, sigma, p, color)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./masks_adaptative_RGB/mask_{frame}.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jlopezcamu/shared/Master/M6/week2/background_remover.py\u001b[0m in \u001b[0;36mcleanMask\u001b[0;34m(mask, roi)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopening\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/core/src/arithm.cpp:212: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'binary_op'\n"
     ]
    }
   ],
   "source": [
    "singleGaussianDetections = remove_background_adaptative_color(means,stds, data_path + 'vdo.avi',data_path + 'roi.jpg',4,2,0.07, \"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs, precs, aps = ap_wo_conf(gt_detect,singleGaussianDetections)\n",
    "plot_prec_recall_curve(np.mean(precs, axis=0), recs[0], f'Precision-Recall curve for Adatative Gaussian  - AP {np.mean(aps)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b57afa678a37970e2ae1e97bfae723b2640c4399908e06bd470e86425548b2c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
